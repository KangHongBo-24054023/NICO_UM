#!/usr/bin/env python


import logging
import random
import time
import threading

import cv2
import numpy
import tensorflow as tf

import GUIController
import imageProcessingUtil
import modelDictionary
import modelLoader


class EmotionRecognitionBackend:
    def __init__(
        self, showGUI=True, faceDetectionDelta=10,
    ):
        """
        Initialises the EmotionRecognition

        :param faceDetectionDelta: Number of frames until face detection is
                                   refreshed
        :type faceDetectionDelta: int
        """
        self._logger = logging.getLogger(__name__)
        self._finalImageSize = (
            1024,
            768,
        )  # Size of the final image generated by the demo
        # Initial position for adding the categorical graph in the final image
        self._categoricalInitialPosition = 260
        # Input size for both models: categorical and dimensional
        self._faceSize = (64, 64)
        self._face_center = None
        self._categoricalRecognition = None
        self._dimensionalRecognition = None
        self._face_detected = False
        self._running = True

        self._modelCategorical = modelLoader.modelLoader(
            modelDictionary.CategoricaModel
        )
        # self._modelDimensional = modelLoader.modelLoader(
        #     modelDictionary.DimensionalModel
        # ) # FIXME does not work under python 3
        self._graph = tf.get_default_graph()

        self._faceDetectionDelta = faceDetectionDelta
        self._imageProcessing = imageProcessingUtil.imageProcessingUtil(
            faceDetectionDelta
        )

        self._GUIController = GUIController.GUIController()

        self._showGUI = showGUI

        if showGUI:
            self.gui_image = numpy.zeros(
                (self._finalImageSize[1], self._finalImageSize[0], 3), dtype="uint8"
            )
            cv2.putText(
                self.gui_image,
                "Waiting for client to send camera image",
                (self._finalImageSize[0] // 3, self._finalImageSize[1] // 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

            def gui_thread():
                while self._running:
                    if self.gui_image is not None:
                        cv2.imshow("Visual Emotion Recognition", self.gui_image)
                        if cv2.waitKey(1) & 0xFF == ord("q"):
                            self._running = False
                cv2.destroyAllWindows()

            self._thread = threading.Thread(target=gui_thread)
            self._thread.daemon = True
            self._thread.start()

    @property
    def face_detected(self):
        """
        Whether a face was detected in the current frame

        :return: True if a face was detected, False if not
        :rtype: bool
        """
        return self._face_detected

    # def getDimensionalData(self):  # FIXME add back in if dimensional model is readded
    #     """
    #     Returns the dimensional data of the currently detected face (or None
    #     if there is none)
    #
    #     :return: Arousal and Valence score (or None if no face detected)
    #     :rtype: dict
    #     """
    #     if not self._running:
    #         self._logger.warning(
    #             "Dimensional data requested while emotion recognition not " + "running"
    #         )
    #         return None
    #     if self._dimensionalRecognition is None:
    #         self._logger.info("No face detected - Dimensional data will be 'None'")
    #         return None
    #     return dict(
    #         zip(
    #             self._modelDimensional.modelDictionary.classsesOrder,
    #             map(
    #                 lambda x: float(float(x[0][0]) * 100), self._dimensionalRecognition
    #             ),
    #         )
    #     )

    def get_categorical_data(self):
        """
        Returns the categorical data of the currently detected face (or None if
        there is none)

        :return: Neutral, Happiness, Surprise, Sadness, Anger, Disgust, Fear
                 and Contempt percentages (or None if no face detected)
        :rtype: dict
        """
        if self._categoricalRecognition is None:
            self._logger.warning("No face detected - Categorical data will be 'None'")
            return None
        return dict(
            zip(
                self._modelCategorical.modelDictionary.classsesOrder,
                self._categoricalRecognition[0],
            )
        )

    def get_highest_matching_emotion(self):
        """
        Returns the name of the highest matching emotion for the currently
        detected face (or None if there is none)

        :return: Neutral, Happiness, Surprise, Sadness, Anger, Disgust, Fear or
                 Contempt (or None if no face detected)
        :rtype: String
        """
        if self._categoricalRecognition is not None:

            if self._categoricalRecognition[0][6] > 15:
                return "fear"
            elif self._categoricalRecognition[0][4] > 20:
                return "anger"
            elif self._categoricalRecognition[0][3] > 15:
                return "sadness"
            elif self._categoricalRecognition[0][3] > 20:
                return "happiness"
            return self._modelCategorical.modelDictionary.classsesOrder[
                numpy.argmax(self._categoricalRecognition[0])
            ].lower()
        return None

    def update_GUI(self, frame, facePoints):
        """
        Updates gui with the detected face and corresponding emotion

        :param frame: Current frame from the camera
        :type frame: cv2.image
        :param facePoints: dict containing "top", "left", "bottom", "right"
                           points of the detected face
        :type facePoints: dict
        """
        frame = self._GUIController.createDetectedFacGUI(
            frame,
            facePoints,
            self._modelCategorical.modelDictionary,
            self._categoricalRecognition,
        )
        # frame = self._GUIController.createDimensionalEmotionGUI(
        #     self._dimensionalRecognition,
        #     frame,
        #     self._categoricalRecognition,
        #     self._modelCategorical.modelDictionary,
        # ) # FIXME add back in if dimensional model is readded
        frame = self._GUIController.createCategoricalEmotionGUI(
            self._categoricalRecognition,
            frame,
            self._modelCategorical.modelDictionary,
            initialPosition=self._categoricalInitialPosition,
        )
        return frame

    def send_image(self, frame):
        """
        Performs face detection and emotion recognition on the given image

        :param frame: frame
        """
        if frame is not None:
            self._logger.info("detecting face")
            facePoints, face = self._imageProcessing.detectFace(frame)

            if self._showGUI:
                image = numpy.zeros(
                    (self._finalImageSize[1], self._finalImageSize[0], 3), numpy.uint8
                )
                image[0:480, 0:640] = frame
                frame = image

            if face is not None and len(face) > 0:
                self._face_detected = True
                self._face_center = facePoints["center"]
                self._logger.info("predicting emotions")
                face = self._imageProcessing.preProcess(face, self._faceSize)
                with self._graph.as_default():
                    self._categoricalRecognition = self._modelCategorical.classify(face)
                    # FIXME add back in if dimensional model is readded
                    # self._dimensionalRecognition = self._modelDimensional.classify(face)

                if self._showGUI:
                    self._logger.info("updating GUI")
                    frame = self.update_GUI(frame, facePoints)
            else:
                self._face_center = None
                self._face_detected = False
                self._categoricalRecognition = None
                self._dimensionalRecognition = None
            # Display the resulting frame
            if self._showGUI:
                self.gui_image = frame

    def get_face_center(self):
        """
        Returns the center coordinates of the currently
        detected face (or None if there is none)

        :return: (x, y) coordinates within the image
        :rtype: (int, int)
        """
        if self._face_center is not None:
            return (self._face_center.x, self._face_center.y)
        else:
            return None

    def close(self):
        self._running = False
        if self._showGUI:
            self._thread.join()
